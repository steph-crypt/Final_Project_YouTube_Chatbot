1
00:00:00,000 --> 00:00:04,320
You got to word here, assemblodes. Yes. That sounds like somebody just made that.

2
00:00:05,040 --> 00:00:09,200
Once we figured out how to make some of this brain region, putting them together,

3
00:00:09,200 --> 00:00:13,919
essentially was unleashing like new forces of self-organization, which is really what the brain does.

4
00:00:13,919 --> 00:00:17,760
I mean, the brain builds itself at the end of the day. Very often when we do this experiment in the

5
00:00:17,760 --> 00:00:21,920
dish, you better know like the instructions and provide them at the right time. You don't start

6
00:00:21,920 --> 00:00:26,480
building a new house until you really have a very clear plan and the tools. In biology actually,

7
00:00:26,559 --> 00:00:31,760
you know, cells come with the instructions. That's what we call this process, self-organization.

8
00:00:31,760 --> 00:00:35,520
So if you were around in Frankenstein's day, Frankenstein would have just been a regular

9
00:00:35,520 --> 00:00:37,920
joke on the street. Yeah. Hey Ben, hey, what's going on?

10
00:00:44,960 --> 00:00:50,560
This is Star Talk, the old grass-tice in your personal astrophysicist. And today it's going to be

11
00:00:50,560 --> 00:00:56,079
special edition, which means we got Gary or Riley Gary. Right, man. Yeah. It was good to have you.

12
00:00:56,559 --> 00:01:02,879
That's just mine. Very good. And Chuckie, baby. Hey, man. All right. Not good to have me, I guess.

13
00:01:02,879 --> 00:01:08,560
Okay. Okay. Good to have you. Gary, always good to have you and and Chuck.

14
00:01:11,599 --> 00:01:17,199
So you got a word here, assemblodes. Yes. That sounds like somebody just made that.

15
00:01:18,159 --> 00:01:24,640
Just assembled it. Yeah. assemblodes. Well, this is a show on assemblodes. What can you tell us about it?

16
00:01:24,640 --> 00:01:29,760
All right. Not that long ago, we did a show on synthetic biological intelligence or if you

17
00:01:29,760 --> 00:01:36,239
prefer, organized intelligence, organized. Yes. I remember. Right. Now, and those are, if I remember,

18
00:01:36,879 --> 00:01:44,480
like 3D cultures to build brain-like structures for bio-computing. Right. So that's what that was

19
00:01:44,480 --> 00:01:50,480
being used for. For our future overlords. All right. So this was putting biology onto technology.

20
00:01:50,480 --> 00:01:56,400
This is something different. However, it's based around the organite in terms of, but this now becomes

21
00:01:56,960 --> 00:02:04,880
organized assembling together. Oh, now that then, self-organizing, organized. So I'll guess today.

22
00:02:06,000 --> 00:02:13,840
So we just, okay, we'll get an answer with, baby. What could go wrong? Let's not do that question,

23
00:02:13,840 --> 00:02:18,240
just. Okay. I'll say that for the end. Yeah. Okay. Go. So I'll guess today. I had the great idea of

24
00:02:18,240 --> 00:02:23,439
trying to get these organoids to work together and coined the phrase, assemblodes. So

25
00:02:23,439 --> 00:02:29,520
assemblodes is down to our guesswork. Now, these assemblodes can help us uncover the biological

26
00:02:29,520 --> 00:02:37,760
mysteries of our own mind. So are we just clumps of cells in the big petri dish we can call life?

27
00:02:37,760 --> 00:02:44,000
Yes. I think sometimes, speak for yourself. Sometimes it can feel like that. So let's find our guess.

28
00:02:44,000 --> 00:02:49,599
Say in a petri dish of life. Yes. That was beautiful. Well, you're welcome. I'm just reading it. And

29
00:02:51,680 --> 00:02:57,039
so let's, let's see what mysteries have been sold. What mysteries are still out there. And our

30
00:02:57,039 --> 00:03:02,879
guess now. So dropping on our guest. Yes. Please. So we have Sergio Paska. Sergio, welcome to

31
00:03:02,879 --> 00:03:08,000
Star Talk. It was great to be here. Thank you so much for having me. Yeah. So you're a neuroscientist

32
00:03:08,000 --> 00:03:12,879
on Star Talk special edition. We love neuroscientists because that there's a serious future

33
00:03:12,879 --> 00:03:18,159
opening up right before our eyes. Yes, it is. In plain in plain sight. A fresh frontier.

34
00:03:18,159 --> 00:03:25,280
Fresh frontier. A stem cell biologist. Stem cells have been pretty much in the news on and off.

35
00:03:25,280 --> 00:03:33,199
Yeah. A couple of decades. Yeah. Professor psychiatry and behavioral sciences at Stanford. When I

36
00:03:33,199 --> 00:03:39,199
think about this, however, I think of a psychiatrist or behavioral scientist, they're just putting

37
00:03:39,199 --> 00:03:44,159
someone in a couch who are observing their behavior. This sounds way more invasive. What

38
00:03:44,159 --> 00:03:51,919
is your doing? It sounds very puppeteerish. Exactly. And you've also been tending. That's good.

39
00:03:51,919 --> 00:04:00,639
So we can dig you up in the Ted archives. Correct. Yeah. Excellent. And here in 2023, you made a

40
00:04:00,639 --> 00:04:07,599
night of the order of merit of Romania. Oh, all right. So let's get back to basics here and put

41
00:04:07,599 --> 00:04:18,480
us on the same page with what an organoid is. So an organoid is a clump of cells that is cultured

42
00:04:18,480 --> 00:04:25,839
in a dish in a three-dimensional structure. And the name actually organoid, which is organ-like,

43
00:04:26,480 --> 00:04:32,560
is supposed to suggest that it resembles an organ. So it's similar in some function. Of course,

44
00:04:32,560 --> 00:04:38,879
it's not a replica of an organ, but is supposed to model features of an organ.

45
00:04:38,879 --> 00:04:45,280
This is so in the case of a scaffold of an organ. I guess like parts of an organ or like parts

46
00:04:45,280 --> 00:04:50,240
of the function of an organ. So for instance, for the brain, it's not really a brain in miniature.

47
00:04:50,240 --> 00:04:54,720
It's not the entire organ in miniature, but it would be like parts or aspects of the brain

48
00:04:55,600 --> 00:05:01,600
that are being modeled. And by the way, asteroids, they show up as stars on a photo because they're so

49
00:05:01,600 --> 00:05:09,120
tiny, but they're not stars. So that they're asteroids. So it's organ-like, I guess the same

50
00:05:09,120 --> 00:05:16,879
as you like star-like. Oh, wait. So those are organoids. Yes. All right. And so now, so now you

51
00:05:16,879 --> 00:05:21,760
organize them in some way, or do they self-organize? You give them instructions that they follow?

52
00:05:22,640 --> 00:05:27,040
Well, I guess all of this work to be honest, like, started with the ability to actually even

53
00:05:27,040 --> 00:05:31,439
grow stem cells in a dish. If you were to, like, step back and think like how this all came

54
00:05:31,439 --> 00:05:37,760
together, you know, stem cells, as you know, generally are derived, you know, from an embryo.

55
00:05:39,040 --> 00:05:43,840
And that has been certainly like very difficult to do studies. But then about-

56
00:05:43,840 --> 00:05:50,960
We're certainly politically fraught with issues related to the ethics of using human embryos.

57
00:05:51,039 --> 00:05:56,799
Right. And that was a big issue until you guys figured out where your people figured out how to

58
00:05:56,799 --> 00:06:00,719
create stem cells without a regular cell, the out of regular cells. So this is-

59
00:06:00,719 --> 00:06:06,799
Well, that happened 20 years ago, almost almost 20 years ago, 19 years ago, when a Japanese

60
00:06:06,799 --> 00:06:12,719
scientist, Shiniya Yamannaka made this like breakthrough discovery, where he actually showed that

61
00:06:12,719 --> 00:06:17,359
you could actually turn any cell that we have in our body, but it's already differentiated.

62
00:06:17,360 --> 00:06:22,480
So like back in time to look like those embryonic stem cells. And so almost like a,

63
00:06:23,600 --> 00:06:28,160
you know, so like cellular alchemy, so to speak, right? Because it was like, we always thought that

64
00:06:28,160 --> 00:06:32,800
it's a one-way street development is a one-way street. You never so like go back.

65
00:06:32,800 --> 00:06:37,680
Just to run the same page, stem cells, while it's always in the news, just as a reminder

66
00:06:37,680 --> 00:06:44,000
to the nonbiologist, it is a kind of cell that you, under the right conditions, can turn into

67
00:06:44,000 --> 00:06:49,759
any other cell of the human body. Is that correct? Exactly. Yeah. It has nerve cells, muscle cells,

68
00:06:51,360 --> 00:06:55,680
and that's why they're prevalent in the embryo because the embryo is manufacturing the-

69
00:06:55,680 --> 00:06:56,079
Of the cells.

70
00:06:56,079 --> 00:06:56,240
The cells.

71
00:06:56,240 --> 00:06:56,480
The cells.

72
00:06:56,480 --> 00:06:56,879
The cells.

73
00:06:56,879 --> 00:06:57,199
Right.

74
00:06:57,199 --> 00:06:57,759
Exactly.

75
00:06:57,759 --> 00:06:58,160
Gotcha.

76
00:06:58,160 --> 00:07:03,120
The stem cells have two properties. They can turn into any other cells and they can renew

77
00:07:03,120 --> 00:07:07,519
themselves. So they can stay as stem cells for a very long time. And of course, there are multiple

78
00:07:07,519 --> 00:07:12,560
levels of stem cells. The first ones are the ones that are the most powerful. They can turn to

79
00:07:12,560 --> 00:07:16,959
everything. And then as you progress in development, they become more and more restricted in what they

80
00:07:16,959 --> 00:07:23,360
can do. But the ones that are really in the beginning are the ones that you would like to have so

81
00:07:23,360 --> 00:07:28,879
that you can ultimately guide them to become different other cells and tissues in the body.

82
00:07:28,879 --> 00:07:32,399
So you put them in a time machine. Is that that box that's sitting behind you?

83
00:07:34,000 --> 00:07:40,079
You say that. But how is that possible? How are you able to take a brain cell that you've

84
00:07:40,079 --> 00:07:46,719
cultured and dial it back to a stem cell and then bring it into whichever area you need to

85
00:07:46,719 --> 00:07:52,240
bring it to? So it was really a brilliant idea. The build on work that was done before.

86
00:07:54,240 --> 00:08:00,240
Essentially, the experiment was very simply done. He just looked at the main genes that are express

87
00:08:00,959 --> 00:08:06,639
in the stem cells. And then he said, let's see which ones are really important. So he took them

88
00:08:06,719 --> 00:08:12,240
and he put them in a actually in the skin cell, took a skin cell and starting putting various

89
00:08:12,240 --> 00:08:19,039
combinations of those genes that are very strongly present in those stem cells. And through this

90
00:08:19,039 --> 00:08:28,159
combinatorial experiment, he found out for that if you put at the same time, pretty much confused

91
00:08:28,159 --> 00:08:33,840
the cell, so to speak, and the cell becomes reprogrammed. That's what we call it cell reprogramming.

92
00:08:33,840 --> 00:08:37,440
Because the cell is really reprogrammed to that state and it turns out that they have all the

93
00:08:37,440 --> 00:08:42,720
properties of those embryonic stem cells. But you can make them from anybody in a non-invasive way.

94
00:08:42,720 --> 00:08:49,120
And of course, you can store them, you can ship them to others. And so that was really a breakthrough

95
00:08:49,120 --> 00:08:54,240
for the field because that opened up the possibility for the first time that you could get stem cells

96
00:08:54,240 --> 00:08:59,759
from anybody from any patient and then start to study it in addition. I was finishing my clinical

97
00:08:59,759 --> 00:09:05,519
training around that time and really to a large extent dropped everything because my expertise,

98
00:09:05,519 --> 00:09:09,600
I'm a physician by training my expertise is actually autism spectrum disorders and neurodevelopmental

99
00:09:09,600 --> 00:09:15,439
conditions. And I was incredibly frustrated by the lack of models to study disease.

100
00:09:15,439 --> 00:09:22,639
We, there are animal models, but what is an animal model of autism? That has been to a challenging

101
00:09:22,639 --> 00:09:29,519
aspect. We can't really access the human brain. That is sort of the, this curse, this unbearable

102
00:09:29,600 --> 00:09:34,720
inaccessibility of the human brain. I mean, it's behind the skull and unlike any other organ,

103
00:09:34,720 --> 00:09:40,319
you can't just go there, get a biopsy and study it. So we were sort of like blocked, so to speak,

104
00:09:40,319 --> 00:09:46,399
blocked into this state where we couldn't really make progress. And yeah, so about 16,

105
00:09:46,399 --> 00:09:53,439
17 years ago, I came to Stanford, mesmerized by the potential of this stem cells that we can make,

106
00:09:53,439 --> 00:09:58,799
which we called induced pluripotent stem cells. And then started thinking, could we actually

107
00:09:58,799 --> 00:10:04,719
turn them into neurons from patients and then study whatever defects are characteristic of

108
00:10:04,719 --> 00:10:09,279
that disease, but outside of the human body. And that's really what enabled all of this. And

109
00:10:09,279 --> 00:10:14,240
initially, that blew up in the whole field at that point. Exactly. The open all field. And in the

110
00:10:14,240 --> 00:10:18,959
beginning, just to make it clear, it was, I mean, I got all the grants and all the fellowships

111
00:10:18,959 --> 00:10:24,719
rejected all the time as this being absolutely insane. How can you actually make neurons in the

112
00:10:24,960 --> 00:10:28,720
dish? And then even expect to find something from a disease that is so mysterious, right? Think

113
00:10:28,720 --> 00:10:33,279
about, I mean, autism is a complex disease of social behavior. What are you going to see actually in

114
00:10:33,279 --> 00:10:38,800
the dish? So I mean, we'll get back probably to this conversation, but it was actually key for us

115
00:10:38,800 --> 00:10:44,240
to focus on a disease where we actually like knew what to expect, sort of like to calibrate. And

116
00:10:44,240 --> 00:10:48,000
that sort of like started that, you know, this entire journey. And in the beginning,

117
00:10:48,000 --> 00:10:51,440
most of these experiments were very simple. You know, you would take the stem cells from patients

118
00:10:52,320 --> 00:10:58,240
that we derive in a dish and then kind of like spike in various molecules in a dish. So like

119
00:10:58,240 --> 00:11:02,640
guide them to try to become neurons. And those differentiation experiments were like easy. But then

120
00:11:03,360 --> 00:11:08,880
about 10 years ago, it became clear that we're going to need more of the three-dimensional aspect

121
00:11:08,880 --> 00:11:13,680
of development to really capture even more complex features of the brain. And that's how some of

122
00:11:13,680 --> 00:11:18,320
these three cultures, which are now known as organoids appear first. So if the neurons are so

123
00:11:18,320 --> 00:11:26,240
organizing, how do they know that they're self-organizing and how do they know where to go and be

124
00:11:26,240 --> 00:11:32,080
organized? That's a very good question. And, you know, I mean, self-organization is a remarkable

125
00:11:32,080 --> 00:11:36,480
force of nature and biology, right? And very often when we do this experiments in a dish, to be

126
00:11:36,480 --> 00:11:41,760
honest, for very long time, I was still like thinking like an engineer in the says that all if you

127
00:11:41,760 --> 00:11:46,320
want to build something in a dish, let's say a circuit, you know, you better so like know the

128
00:11:46,320 --> 00:11:51,120
blueprint, you better know like the instructions and provide them at the right time. And so you don't

129
00:11:51,120 --> 00:11:56,960
start building a new house until you really have a very clear plan into tools. But what we realize

130
00:11:56,960 --> 00:12:02,640
with time is that in biology, actually, you know, cells come with the instructions, you know, so once

131
00:12:02,640 --> 00:12:07,840
you make a specific cell, they'll actually come with the instruction. And then by connecting, let's

132
00:12:07,840 --> 00:12:12,800
say to another cell, it reveals another set of instructions. Right. And another one and another

133
00:12:13,039 --> 00:12:18,159
one. And that's what we call this process self-organization. So which really is the formation of

134
00:12:18,159 --> 00:12:23,919
or the structure from, you know, relatively homogenous elements, which which by the way, like talking

135
00:12:23,919 --> 00:12:28,879
of physics and chemistry, this was known from the 19th century. I mean, there are classic experiments

136
00:12:28,879 --> 00:12:33,759
that show, you know, that molecules organize quite beautifully, you know, the Riley Bernard

137
00:12:33,759 --> 00:12:39,039
convection, I guess is the classic example. But biology just brings it to the next level. And now

138
00:12:39,120 --> 00:12:44,000
organize the cells pretty much on their own. So what you're doing is you're bringing these

139
00:12:44,000 --> 00:12:52,639
together in this culture, this 3D culture, where the message and directions are already resident

140
00:12:52,639 --> 00:12:59,199
inside of the cell. So when you put them together or group them, they basically do what they

141
00:12:59,199 --> 00:13:06,719
were going to do anyway. Exactly. Okay. With with with we want detail, which is we have to make the

142
00:13:06,720 --> 00:13:11,759
parts right. If you don't have the right parts, then of course they won't know what to do. What to

143
00:13:11,759 --> 00:13:17,279
do? Actually, what we spend a lot of time generally is making the part. Let's think about the human

144
00:13:17,279 --> 00:13:21,759
brain. I mean, the reason why the human brain is remarkable is because it has all these parts,

145
00:13:21,759 --> 00:13:26,240
which are very different. You know, unlike, let's say, the liver, the liver is relatively homogenous,

146
00:13:26,240 --> 00:13:32,480
right? A few cell types can like any part is like any other. You look at the brain and now you have

147
00:13:32,560 --> 00:13:36,480
thousands of cell types. I mean, the recent estimates, you know, say that they're probably

148
00:13:36,480 --> 00:13:41,600
2000 cell types just in the human brain, right? Scatter through this nuclei and regions.

149
00:13:42,320 --> 00:13:47,360
And the remarkable abilities of the brain really result from the cells interacting with each other.

150
00:13:48,000 --> 00:13:52,560
So in the early days, like you know, 15 years ago, we were making just a few cells,

151
00:13:52,560 --> 00:13:57,920
like a few spinal cord neuron cells or maybe a few cortical neurons. But then we've never really

152
00:13:57,920 --> 00:14:01,840
leveraged the ability of the cells to connect with each other. And so that's where essentially

153
00:14:01,840 --> 00:14:06,560
a sample, it's came where once we figure out how to make some of the cell types, some of these

154
00:14:06,560 --> 00:14:13,040
brain regions, putting them together, essentially, you know, was unleashing like new forces of self-organization,

155
00:14:13,040 --> 00:14:16,720
which is really what the brain does. I mean, the brain builds itself at the end of the day. You

156
00:14:16,720 --> 00:14:21,840
know, if you think about it, right? And it reorganizes itself. Like if you damage a part of your brain,

157
00:14:21,840 --> 00:14:27,920
it will reorganize itself so that that function might be taken up someplace else.

158
00:14:28,399 --> 00:14:32,879
At least early in development. Yes. Early in development, it will do so. And then the more you

159
00:14:32,879 --> 00:14:37,759
progress, the, you know, the less you can use that. The less that happens, right? What if you leave

160
00:14:37,759 --> 00:14:43,679
your culture brain cells in the dish for nine months a year? What happens to them?

161
00:14:43,679 --> 00:14:48,240
Do they just take care of business on their own or that they just fade away? Something crawls out

162
00:14:48,240 --> 00:14:53,679
of the piece you're dashing. You have the smartest dish in the world. It'll chase you down the car.

163
00:14:54,639 --> 00:15:00,079
Get that fork away from me. Well, that was something actually, you know, really fascinating

164
00:15:00,079 --> 00:15:05,599
that we discovered like, you know, almost 10 years ago. So at one point, we were, you know,

165
00:15:05,599 --> 00:15:10,399
my lab was still like in the early days. And at one point, you know, we realized that,

166
00:15:10,959 --> 00:15:15,279
well, I mean, at this our expensive experiments, you have to keep feeding the cells and I was running

167
00:15:15,279 --> 00:15:20,000
out of money in the lab. And so I told everybody in the lab, I said, you better go and your incubators.

168
00:15:20,639 --> 00:15:24,960
And like make sure that you're not maintaining cultures that we don't need. We need to focus.

169
00:15:24,960 --> 00:15:29,360
We need to save money. And then somebody in the lab comes and says, oh, should I also like remove

170
00:15:29,360 --> 00:15:34,559
the ones that are like 300 days old? I was like, what do you mean 300 days old? It's like, yeah, I mean,

171
00:15:34,559 --> 00:15:38,799
you know, I knew that we were keeping them for very long periods of time, but I had no idea that

172
00:15:38,799 --> 00:15:42,720
we could keep them for such a long period of time. And it turns out that once you make this

173
00:15:42,720 --> 00:15:47,279
cluster of cells and, you know, so like, I wish I could show you, I wish you were here in the lab

174
00:15:47,360 --> 00:15:50,319
and I could show you, and maybe I can try, but they look something like this.

175
00:15:50,959 --> 00:15:54,639
All right. I see it. You see it. Not there a lot. They're still like fixed, you see? So they're like

176
00:15:55,360 --> 00:15:59,919
relatively large clumps of cells. They're floating in the media in the incubators. You

177
00:15:59,919 --> 00:16:03,759
keep going and change media. And then at one point, we realized we can keep them for very

178
00:16:03,759 --> 00:16:07,360
long periods of time. In fact, we maintain now the longest cultures that have ever been reported.

179
00:16:07,360 --> 00:16:12,240
Like you can keep them for years. And so now the question was, are they stuck in development?

180
00:16:12,240 --> 00:16:16,959
Are they progressing in development? And through a series of papers, we discover something

181
00:16:17,279 --> 00:16:24,559
really fascinating is like, they actually keep track of time really well. So well that once they

182
00:16:24,559 --> 00:16:30,159
actually arrive at about nine months of keeping them in a dish, they actually transition in terms

183
00:16:30,159 --> 00:16:36,159
of their gene expression and some of the properties of the cells to a postnatal brain. So it's almost

184
00:16:36,159 --> 00:16:40,559
like they know that birth should happen. There's almost until like, we think that there is some sort of

185
00:16:40,559 --> 00:16:46,000
internal clock that keeps track of time. Is this the brain clock that I've read about? Yeah, this is

186
00:16:46,000 --> 00:16:53,600
the brain clock exactly. I'm fascinated now that these cells have the ability to understand

187
00:16:54,240 --> 00:16:59,759
basically a calendar. I mean, because they're not not observing the the sun going across the

188
00:16:59,759 --> 00:17:05,200
sky a day and a night. Yeah. So what's what's what's doing the taking? Exactly. So I mean, you may

189
00:17:05,200 --> 00:17:10,480
think that this is, you know, surprising. But if you think about it, it's not that surprising. I mean,

190
00:17:10,480 --> 00:17:15,680
every time you make a human, you always make it in like 280 days. And here's the interesting thing.

191
00:17:15,680 --> 00:17:23,360
If you take mouse stem cells, okay, or we have like chimp stem cells and you differentiate them

192
00:17:23,360 --> 00:17:29,600
the same way in a dish, they'll finish development in their own time. But in that that same time period

193
00:17:29,600 --> 00:17:35,519
reflects the justation period of a chimp. Like it will be three weeks for the rat. And it will be like,

194
00:17:35,519 --> 00:17:41,360
you know, whatever is for. So this is, I mean, evolution has actually selected, you know, very well

195
00:17:41,359 --> 00:17:46,159
like this periods of development. And so they're intrinsic to the cells. I think what we what was

196
00:17:46,159 --> 00:17:51,359
surprising for us was that this happens also outside of the of the body, right? Outside of the

197
00:17:51,359 --> 00:17:56,319
uterus. Of course, this is not to say that all aspects of development are recapitulated. I mean,

198
00:17:56,319 --> 00:17:59,599
there are all kinds of things that are coming, right? What kind of information is that are coming

199
00:17:59,599 --> 00:18:03,599
that are shaping development that we know that the more you invest in human brain development,

200
00:18:03,599 --> 00:18:09,119
the more the environment is important, like sensory information, right? Like cognitive development

201
00:18:09,279 --> 00:18:13,199
think about motor behavior afterwards. But especially at early stages of development,

202
00:18:13,759 --> 00:18:19,439
everything is quite well regimented and goes according to a calendar. Nobody knows what the clock is.

203
00:18:20,159 --> 00:18:25,439
So nobody knows what the molecular mechanism of it is. But it is somewhere in the cells,

204
00:18:25,439 --> 00:18:30,479
it's something that is counting somehow time and that's why it's such a great time to do neuroscience.

205
00:18:31,439 --> 00:18:36,319
Like more people should like come and do that. So where do these cells derive their energy from?

206
00:18:36,319 --> 00:18:41,200
Because it's not you talk about a clock. There's not a battery in the back. What is powering this?

207
00:18:41,200 --> 00:18:46,079
Because they're outside of the outside of the body. They've not got the whole human system to back it up.

208
00:18:46,720 --> 00:18:53,919
So we feed them. So like a soup of chemicals that is made sort of like in the lab. So we like,

209
00:18:53,919 --> 00:18:58,559
we provide them glucose, right? I mean, they need glucose and some of the amino acids and we give them

210
00:18:58,559 --> 00:19:03,679
lipids, right? And so they need fats. And so we just like have we call them cell culture media.

211
00:19:03,759 --> 00:19:13,039
And how do you measure if and when they are expressing their prescribed function? Because

212
00:19:13,039 --> 00:19:19,519
a neuron has a very specific function. Absolutely. How do you know that they are actually

213
00:19:19,519 --> 00:19:24,560
expressing that function? So we do all kinds of things. Like first of all, we just look to see very

214
00:19:24,560 --> 00:19:30,560
often, you know, cells, I mean, not very often all the time cells have a signature. You know,

215
00:19:30,559 --> 00:19:36,480
they express a certain combination of genes. So generally the first question is if you think you've

216
00:19:36,480 --> 00:19:40,879
made a cortical neuron, let's say a neuron from the outer layer of the brain, how do you know that

217
00:19:40,879 --> 00:19:45,440
it's a cortical neuron? Well, first of all, you kind of like look at what genes it expresses and you

218
00:19:45,440 --> 00:19:50,559
compare it with what we know from a neuron in the actual brain. Then you can look at how it looks.

219
00:19:51,119 --> 00:19:55,599
They're often neurons in the cortex have to like a pyramidal shape. We call them pyramidal neurons.

220
00:19:55,599 --> 00:20:00,159
So you look, do they look pyramidal? That means like a pyramid? Yeah, exactly.

221
00:20:00,159 --> 00:20:07,199
Pyramid dental. Okay. For me, pyramidal. Yeah. They really look like a tiny pyramid.

222
00:20:07,199 --> 00:20:10,480
Okay. Yeah, an inverted pyramid. Like that's how they stood in the cortex. So you look at this

223
00:20:10,480 --> 00:20:16,480
like the shape of the cell body or the other thing is sometimes they move in very specific ways.

224
00:20:16,480 --> 00:20:22,480
And that's actually how the first assemblots were actually looking at how cells are moving. So here,

225
00:20:22,480 --> 00:20:26,319
here's this interesting fact. You know, you may think that you know, you have all the cell types in

226
00:20:26,319 --> 00:20:30,720
the brain, right? But they're all made, you know, when you build the brain, they're all made so

227
00:20:30,720 --> 00:20:37,440
like in their place and then they sit there. Actually, it's more, and you know, a rule rather than an

228
00:20:37,440 --> 00:20:43,279
exception that cells do not reside in the place in which they're born in the brain. So there's a lot

229
00:20:43,279 --> 00:20:48,720
of movement. So think about the cortex, okay? Like the outer layer of the brain. It has neurons,

230
00:20:48,720 --> 00:20:53,279
they're exciting other neurons and it has neurons there inhibiting other neurons. And there is a

231
00:20:53,279 --> 00:20:58,319
very good balance between the two of them. Too much excitation you get epilepsy, right? So,

232
00:20:58,319 --> 00:21:04,240
you know, think about that. No, here's the interesting thing. All the excitatory neurons are born there

233
00:21:04,240 --> 00:21:11,200
in the cortex, but all the neurons that are inhibitory are built in a deep part of the brain. And

234
00:21:11,200 --> 00:21:18,480
literally during brain development, they start moving, crawling for inches and for many, many months,

235
00:21:18,480 --> 00:21:24,640
until they arrive into the cortex and then they kind of establish that balance. So in order for

236
00:21:24,640 --> 00:21:29,519
you to build that cortex, it's not enough just to make the excitatory cells. You have to make the

237
00:21:29,519 --> 00:21:34,960
inhibitor cells. And then the question is, how do they come together? How do they assemble? Because

238
00:21:34,960 --> 00:21:40,160
that's where the name assembly it came. And essentially, the vision was like almost, you know, 12 years

239
00:21:40,160 --> 00:21:45,200
ago was let's make this two parts of the brain, the one that makes the excitatory neurons and the

240
00:21:45,200 --> 00:21:51,039
one that makes the inhibitor neurons and then just put them close to each other. And hopefully the

241
00:21:51,039 --> 00:21:57,360
cells will know what to do because we certainly don't know how to guide them to do more. And it turns

242
00:21:57,360 --> 00:22:02,480
out that exactly what they do, you put them together and this garbageic cells immediately start like

243
00:22:02,480 --> 00:22:06,799
they have this processes, the cellar processes, they start to like smelling where the cortex is

244
00:22:07,519 --> 00:22:11,440
and they literally start jumping. You know, you see the cells, they literally spend three hours,

245
00:22:11,920 --> 00:22:16,240
they look in that direction and then they make a jump 40 microns. Then they wait for another three

246
00:22:16,240 --> 00:22:20,960
hours. Kind of like smell where the cortex is, make another jump. And this process has never really been

247
00:22:20,960 --> 00:22:25,680
seen in humans. This happens in the third trimester of life. But this is this is what's going on in

248
00:22:25,680 --> 00:22:32,400
every developing human being. So professor, what you're saying is basically we have a bunch of cells

249
00:22:32,400 --> 00:22:36,960
that are in a field and they they're looking and they recognize one another and then they just

250
00:22:36,960 --> 00:22:43,120
start running to each other and slow motion. Pretty much, pretty much because they really come with

251
00:22:43,120 --> 00:22:47,759
instructions of how to do this. And I think that's what happens in development. And that's why you build

252
00:22:47,759 --> 00:22:52,480
the brain. I mean, our brains may be a little bit different from each other. But in the grand scheme

253
00:22:52,480 --> 00:22:57,600
of things, they're quite the same. I mean, we have the same structures is not like, you know, you

254
00:22:57,600 --> 00:23:02,720
have a thalamus in the spinal cord, right? We all have pretty much in the same position. So in order

255
00:23:02,720 --> 00:23:08,799
for, you know, the brain to build itself that way, there are these remarkable forces that

256
00:23:09,680 --> 00:23:14,960
bring all the cells together over and over again, every time you build a human brain. Wow.

257
00:23:15,759 --> 00:23:19,680
Okay, this is the last thing I'm sorry. I know we got to move on to the next subject. But here's

258
00:23:19,680 --> 00:23:26,000
what is like percolating in the brain right now. Is this once you kind of

259
00:23:26,960 --> 00:23:33,039
perfect this technology? Would you be able to then introduce these cells and have them go in and

260
00:23:33,680 --> 00:23:39,759
let's say for instance, repair a part of my brain that kind of makes me so stupid. I don't believe in

261
00:23:39,759 --> 00:23:51,039
climate change or something. Well, we're sort of like a self assembly actually works really well

262
00:23:51,039 --> 00:23:56,319
early development in the sense that all the cells are open to like connecting with the others.

263
00:23:57,039 --> 00:24:01,519
But then it turns out that the as you progress in development, the cells become less and less

264
00:24:01,519 --> 00:24:06,079
permissive. We don't have cells moving in our brain right now. Okay. You know, it's just not very

265
00:24:06,079 --> 00:24:11,279
adeptive. So the challenge is that if you start to add the cells into an adult, like those circuits

266
00:24:11,279 --> 00:24:16,399
are already formed. So it's not that easy. You know, um, to the dumbass circuitry, the dumbass circuit

267
00:24:16,560 --> 00:24:24,480
is fully formed and very, very strong. Right. However, if you're able prenatal to identify brain

268
00:24:24,480 --> 00:24:31,680
disorders or any disorder in a child, you might be able during the gestation process to go in and

269
00:24:32,240 --> 00:24:37,680
and make changes. Exactly. And that's exactly what we're actually even early after birth because

270
00:24:37,680 --> 00:24:42,480
the human brain develops for like years, even after we're born. That's amazing. So if Professor,

271
00:24:42,480 --> 00:24:48,160
that that's amazing. All right. So Professor, you did some work and some research with cells

272
00:24:48,160 --> 00:24:53,039
and you said you worked with autism patients and the like. And there's something called Timothy

273
00:24:53,039 --> 00:24:59,279
syndrome, which is autism and epilepsy, which seems a terrible combination to a terrible

274
00:24:59,279 --> 00:25:07,200
epithemathy. Yeah. But you then afflicted cells with this Timothy syndrome. Is that correct?

275
00:25:07,920 --> 00:25:15,200
Yeah. And then reverse engineer it. How you could find a way to work with and do basically what

276
00:25:15,200 --> 00:25:20,160
you said, take that away. Right. Is that could, I mean, I'm explaining that at all well, but

277
00:25:20,160 --> 00:25:25,600
you probably could do it better than I. Yeah. If you would. So I mean, this, this goes back to like,

278
00:25:25,600 --> 00:25:29,759
you know, the previous point when we were talking about how these stem cells were so like

279
00:25:29,759 --> 00:25:35,600
discovered and what their potential was. So the question was if you really want to model a disease,

280
00:25:35,599 --> 00:25:40,559
you want to model a complex disease such as autism and epilepsy, you know, where do you actually

281
00:25:40,559 --> 00:25:46,079
start? I mean, psychiatric disorders are mysterious. These are, we still don't know how like this,

282
00:25:46,079 --> 00:25:51,039
you know, thoughts and this complex social behavior rises in the brain. So actually, we thought we

283
00:25:51,039 --> 00:25:56,559
would start with genetics because one thing that we do know about many of these developmental

284
00:25:56,559 --> 00:26:00,799
disorders is that they're caused by mutations. They're caused by very severe mutations.

285
00:26:00,799 --> 00:26:05,199
All right. Right. So there's this rare, rare syndrome. I mean, literally, we found about

286
00:26:05,200 --> 00:26:10,799
3040 patients in the English speaking world today. Very few, but they have a mutation,

287
00:26:10,799 --> 00:26:18,400
the spations in a protein that is actually a channel for calcium in the cells. Every time a neuron

288
00:26:18,400 --> 00:26:23,759
communicates with another neuron, it opens up this channels. Let's calcium in and it essentially

289
00:26:24,400 --> 00:26:29,759
translates electrical information into chemical information inside the cell. So it turns out that

290
00:26:29,759 --> 00:26:36,559
these patients have one single letter mutation in their entire genome, one single letter that makes

291
00:26:36,559 --> 00:26:43,119
this channel open for a little bit longer. That's it. And it's not all the time open. It's not,

292
00:26:43,119 --> 00:26:49,119
you know, just slightly longer. So the idea was that if you were to model this disease, you could

293
00:26:49,119 --> 00:26:53,920
make neurons from these patients, then look at them and actually monitor calcium inside the cells.

294
00:26:54,480 --> 00:26:58,640
And if we were to see more calcium, it means that we started modeling the disease. And that's

295
00:26:58,640 --> 00:27:04,160
exactly what we did because we wanted to really ascertain that we were really studying a disease

296
00:27:04,160 --> 00:27:09,120
process that is relevant. So if you know the actual letter and when you're talking about that,

297
00:27:09,120 --> 00:27:14,720
you're talking about the DNA sequencing. So if you know the actual letter, why not do something

298
00:27:14,720 --> 00:27:20,240
like CRISPR where you just go in and snip out the letter? Well, sadly, you would have to change it

299
00:27:20,240 --> 00:27:27,920
everywhere in the brain. And that is not, you know, doable to me. Okay. And this patients are very

300
00:27:27,920 --> 00:27:31,440
severely affected. I mean, they'll have epilepsy, they'll have autism spectrum disorder.

301
00:27:31,440 --> 00:27:36,240
They have a heart problem. So many of them would die because of a heart problem. And so that's

302
00:27:36,240 --> 00:27:40,720
that's where we started with with cells from these patients. And then with this model that I've

303
00:27:40,720 --> 00:27:45,440
told you now for the past 15 years, we kept building the models to be more complex and try to

304
00:27:45,440 --> 00:27:50,080
understand these disease. And first went to study how calcium gets into the cells. Then we saw that

305
00:27:50,080 --> 00:27:54,720
the cells are not moving right. They're not connecting property. And about three years ago,

306
00:27:55,519 --> 00:28:01,920
which is, you know, one of the most interesting, you know, times in, in sort of like my academic life

307
00:28:01,920 --> 00:28:08,400
was at one point, we just accumulated enough information about the disease that essentially the

308
00:28:08,400 --> 00:28:13,360
therapeutic just became self evident, so to speak. You're just like, look at it and they're saying,

309
00:28:13,360 --> 00:28:18,160
oh, this makes sense. This is what we need to do. And so I don't want to go into the details of how

310
00:28:18,160 --> 00:28:23,360
we didn't does, but it has to do with how this gene is processed inside the cells with done a screen

311
00:28:23,439 --> 00:28:30,319
and essentially identify a tiny piece of a nucleic acid that if you add to cells, goes right into them,

312
00:28:31,119 --> 00:28:36,399
changes the channel and essentially restores almost every single defect that we've discovered over

313
00:28:36,399 --> 00:28:42,079
the past 15 years. It's like within, you know, a couple of days. This is insane. I know,

314
00:28:42,079 --> 00:28:46,399
but what you're talking about, he's a Sherlock County. This is just real detective work. I mean,

315
00:28:46,399 --> 00:28:52,799
to work out that that is exactly what's necessary. I mean, you said it was obvious, but obviously,

316
00:28:52,799 --> 00:28:56,399
it wasn't. Otherwise, someone would have seen it a long time ago. So if you were around a Frankenstein's

317
00:28:56,399 --> 00:29:00,799
day, Frankenstein would have just been a regular Joe on the street. Yeah, he would have walked out

318
00:29:00,799 --> 00:29:05,039
instead of like, he'd been like, hey, what's going on? Hey, that's feeling.

319
00:29:08,399 --> 00:29:13,119
Are you mapping this with sort of an AI technology? I mean, that CRISPR's one pool, but there are

320
00:29:13,119 --> 00:29:19,279
others out there. Is that what it is? Or is this just the empirical evidence from experiment?

321
00:29:19,279 --> 00:29:23,440
It's a large empirical. I mean, we just, you know, just accumulate enough information about

322
00:29:23,440 --> 00:29:28,079
the biology that at one point, it became clear. And it's quite interesting if you think about it,

323
00:29:28,079 --> 00:29:33,359
because this is could be the first psychiatric disease that has been exclusively understood

324
00:29:33,359 --> 00:29:38,559
with this human stem cell models, meaning by studying it, by studying human brain cells outside

325
00:29:38,559 --> 00:29:43,680
of the body of those patients. Right. And so of course, the question is like, how do you actually,

326
00:29:43,680 --> 00:29:47,839
you know, know that it would work? You know, generally what we do is we use an animal model for the

327
00:29:47,839 --> 00:29:53,039
disease, right? You have an animal model, you have a mouse that has the same mutation, or turns out

328
00:29:53,039 --> 00:29:57,039
that if you do this mutation in a mouse, it doesn't really recapitulate aspects of disease. It

329
00:29:57,039 --> 00:30:01,439
doesn't work that well. So now what do you do? You can also just go straight into a patient. You

330
00:30:01,439 --> 00:30:07,199
want to make sure that sort of like, it works sort of like in an in vivo setting. And so that's why

331
00:30:07,199 --> 00:30:11,839
one of the things that we've done over the past years is actually also develop transplantation methods,

332
00:30:11,839 --> 00:30:17,439
meaning that while the organics and the assemblies that we've been building are rather complex,

333
00:30:17,839 --> 00:30:22,559
they still don't receive sensory input. They don't mature to the same level. So what we started

334
00:30:22,559 --> 00:30:27,599
doing is actually transplanting them, meaning we essentially take the organ that we've made in a

335
00:30:27,599 --> 00:30:32,799
dish, but now we put it into the brain over rat. And then if you do it early in development,

336
00:30:33,359 --> 00:30:39,039
then the rat can actually grow to have about a third of a hemisphere to be made out of human cells.

337
00:30:39,039 --> 00:30:43,039
You can literally see it on an MRI. And you may think, well, this is, you know, why would you even

338
00:30:43,200 --> 00:30:47,599
do that experiment? Well, the reason is because now we actually have human tissue from patients

339
00:30:48,240 --> 00:30:52,879
in a living organism. And you can test the drug. So what we did is we took the drug that we

340
00:30:52,879 --> 00:30:59,119
tested in vitro in a dish, but then injected it into the rat the way he would do into a patient.

341
00:30:59,119 --> 00:31:03,920
But then we looked at the effect on human cells, making sure that it doesn't kill human cells,

342
00:31:03,920 --> 00:31:08,480
whether it doesn't do something else. So that is like one way that allows us actually

343
00:31:08,480 --> 00:31:14,000
to test their putics in a way that is like safe, essentially. So the thing is if you want to

344
00:31:14,799 --> 00:31:21,200
solve the issues of complex brain disorders, you're going to need more complex

345
00:31:22,000 --> 00:31:31,039
assemblots. Now you've taken this assembly up a notch, have you not, and Daisy chained four

346
00:31:31,039 --> 00:31:37,519
organoids together, but then gone down the path of sensory. If you could sort of expand on that

347
00:31:37,599 --> 00:31:41,920
for us, because I think this is absolutely fascinating. You tell me they have feelings.

348
00:31:41,920 --> 00:31:46,960
Is this what you're telling me? No. Yeah, the professor explained. No, you know, I mean, it turns out

349
00:31:46,960 --> 00:31:51,599
that if you if you think about like brain disorders, you know, some of them are sort of like

350
00:31:51,599 --> 00:31:56,079
hardware defects, right? I mean, parts are just missing. Think about in a stroke, right? You like,

351
00:31:56,079 --> 00:32:01,680
you know, you lose like parts of the cortex. But most disorders that we consider today psychiatric,

352
00:32:01,680 --> 00:32:07,440
autism, schizophrenia, we think of them more as like disorders of software of communication

353
00:32:07,440 --> 00:32:12,400
between the cells. So it becomes really clear that if you really want to capture those processes

354
00:32:12,400 --> 00:32:16,560
outside of the human body, we still like need to reconstruct those circuits outside.

355
00:32:17,360 --> 00:32:21,120
And so this started like, you know, maybe five, six years ago when we thought, could we actually

356
00:32:21,120 --> 00:32:28,000
build a circuit that is actually has an output, you know, really easy to measure? So we decided to

357
00:32:28,000 --> 00:32:33,839
reconstruct the cortical spinal pathway. So that means and you know, this really well, everybody

358
00:32:33,839 --> 00:32:40,480
knows this is like biology textbook information. You have a neuron in the cortex that generally

359
00:32:40,480 --> 00:32:45,599
goes all the way to the spinal cord makes a connection or a synapse with the spinal cord neuron

360
00:32:45,599 --> 00:32:51,759
and that spinal cord neuron goes to muscle. You have essentially three neurons, two connections.

361
00:32:51,759 --> 00:32:56,559
You stimulate the cortical neuron information goes down to the spinal cord to the muscle, the muscle

362
00:32:56,559 --> 00:33:02,159
contracts. Right. You know, it's as easy as so like text to biology. So we thought, could we

363
00:33:02,159 --> 00:33:06,480
actually reconstruct this? You may think that it's easy, but here is is we don't know how the cells

364
00:33:06,480 --> 00:33:12,079
find each other in development. By the way, we have no ideas about the rules. So what we did is we made

365
00:33:12,079 --> 00:33:18,159
an organoid that resembles the cortex, one that resembles the spinal cord and then we made a ball

366
00:33:18,159 --> 00:33:23,200
of human muscle from a biopsy, you can get a biopsy of muscle, build it as a ball and then we put

367
00:33:23,200 --> 00:33:29,039
them all together and it turns out that once you do this, those specialized neurons in the cortex,

368
00:33:29,039 --> 00:33:34,240
not every cortical neuron, but the ones that really go to the spinal cord start to leave the cortex,

369
00:33:34,960 --> 00:33:40,319
find the motor neurons, then the motor neurons leave and find the muscle and then the three

370
00:33:40,319 --> 00:33:45,840
preparations starts to contract. Well, that would that was a three-part assembly. All right. And

371
00:33:45,840 --> 00:33:50,880
that that told us that even you know, against the odds because the probabilities for the cells to

372
00:33:50,880 --> 00:33:56,560
find each other is very, very low and yet this works beautifully and you can actually stimulate

373
00:33:56,560 --> 00:34:00,960
the cortex and you get beautiful muscle contractions. And we've been using this, you know,

374
00:34:00,960 --> 00:34:05,920
really in the last years to identify, for instance, how polio virus and other non-polio

375
00:34:05,920 --> 00:34:11,200
enteroviruses actually affect the spinal cord and cause paralysis, which is very difficult to study

376
00:34:11,200 --> 00:34:16,720
otherwise. So it is a very important so like preparation, you can add this polio virus and you can

377
00:34:16,719 --> 00:34:21,839
cause a paralysis of that circuit in a dish. This work is not yet published, but it tells you like

378
00:34:21,839 --> 00:34:28,399
just how useful a preparation like this can be. It's beyond useful. I mean, what I'm trying to figure,

379
00:34:28,399 --> 00:34:38,239
not figure out, envision is a time where we've mapped like everything, right? So you have,

380
00:34:38,239 --> 00:34:43,599
you have the layout. Now, would there be a time because of what you're saying that we'll be able to

381
00:34:43,599 --> 00:34:54,239
go in, identify in a child that is developing in the womb and then identify mutations and then

382
00:34:55,039 --> 00:35:03,920
take the assemblots, put them into the child and have those mutations corrected before the child

383
00:35:03,920 --> 00:35:10,079
is born. Is that the deal? Perhaps even an easier scenario for that. Okay. Is that have a mutation?

384
00:35:10,559 --> 00:35:16,319
You know that a patient will have a serious mutation. You build an assemblot that models the

385
00:35:16,319 --> 00:35:21,759
disease of that patient without using the patient brain. So like an avatar if you want, right? I mean,

386
00:35:21,759 --> 00:35:27,199
that's what an assemblot is. If you think about it, right? It's an avatar for that circuit. Simplified

387
00:35:27,199 --> 00:35:33,279
in a dish, you test a drug or you screen for drugs. Maybe you want to screen quickly for drugs.

388
00:35:33,279 --> 00:35:37,360
Right. And then you use that in a patient. So now you can do that for every single patient. You

389
00:35:37,360 --> 00:35:43,599
don't have to actually do the process in any particular patient because now you developed a drug

390
00:35:44,079 --> 00:35:49,519
for the mutation itself. Now just boom, boom, boom, every single person with that mutation gets that

391
00:35:49,519 --> 00:35:54,320
drug delivered and that's how you, wow, that's amazing. But you get there. We do need to get a

392
00:35:54,320 --> 00:35:59,519
better understanding of how because you see where quite why do wait, why do you have to understand

393
00:35:59,519 --> 00:36:04,000
why the cells do what they do? They're doing it. You already know why do you have to, are you just

394
00:36:04,000 --> 00:36:09,840
a new scientist? That's right. Because he said, look at, look at Neil, look at that. We're like,

395
00:36:09,840 --> 00:36:14,400
how dare you just science it. We don't accept just what is.

396
00:36:17,199 --> 00:36:22,639
It actually think about like Richard Feynman. He famously said, and I'm sure you know this,

397
00:36:22,639 --> 00:36:28,239
that what I cannot create, I do not understand. And you know, if you think a little bit about this,

398
00:36:28,879 --> 00:36:34,399
if we cannot recreate the circuits outside, it's going to be difficult for us to understand. And if

399
00:36:34,399 --> 00:36:40,079
we don't understand the biology, all the breakthroughs in medicine that came over the last decades,

400
00:36:40,079 --> 00:36:46,719
think about cancer in children, right? In the 60s, 90% lethal. Today, less than 10% lethal.

401
00:36:47,519 --> 00:36:53,439
Why this entire revolution, molecular biology? Because the tissue of inches was accessible. You get

402
00:36:53,440 --> 00:36:58,880
the blood of these patients in leukemia or the tumor. You bring it to the lab and you deploy the

403
00:36:58,880 --> 00:37:04,240
power of molecular biology. We in psychiatry and neurology are really the last ones because we

404
00:37:04,240 --> 00:37:10,400
cannot access the brain. So my belief is that as we gain access to the brain through this methods

405
00:37:10,400 --> 00:37:15,039
and others, noninvasively, we're going to be able to deploy the power of molecular biology and

406
00:37:15,039 --> 00:37:19,920
make breakthroughs in molecular, you know, psychiatry and neurologism, we've done in, you know,

407
00:37:20,880 --> 00:37:25,280
cardiology and other branches of medicine. That's sort of like how I see it, but I may be wrong.

408
00:37:25,280 --> 00:37:29,840
But haven't you got an Assembloid now that's like I said, a four-stage Assembloid, but you've

409
00:37:29,840 --> 00:37:36,559
worked it so as it's sensory and you can feel the understanding of pain and then how that becomes

410
00:37:37,200 --> 00:37:42,800
hypersensitivity or to the point where people do not feel pain at all. Oh, okay, I thought you

411
00:37:42,800 --> 00:37:46,800
meant like they're going to have that little vial of assemblies just screaming in the middle of the

412
00:37:46,800 --> 00:37:56,320
night. No, why did you keep me playing? Not that one. You know, you're right that one of the things

413
00:37:56,320 --> 00:38:00,480
that we're trying, actually, this just came out. I mean, we made the first Assembloid in like

414
00:38:00,480 --> 00:38:06,240
2017. It took us three years to make go from two parts Assembloids to three parts Assembloids,

415
00:38:06,240 --> 00:38:10,080
the one with the motor that I was explaining. And then it took us another five years to get to

416
00:38:10,080 --> 00:38:14,640
four parts Assembloids just because it's technically more and more complicated. And this is the

417
00:38:14,719 --> 00:38:19,599
pathway that sends is, you know, sensory information. So think about it. If you, you know, want to

418
00:38:19,599 --> 00:38:24,960
sense anything, even a painful stimulus on a finger, you have nerve terminals that are coming from

419
00:38:24,960 --> 00:38:30,879
neurons that sit close to the spinal cord. They have receptors that sense that then they send that

420
00:38:30,879 --> 00:38:36,319
information to the spinal cord. The spinal cord shoots that information up to the thalamus in the middle

421
00:38:36,319 --> 00:38:40,639
of the brain and the thalamus sent it to the cortex and then you sense that something happened.

422
00:38:41,359 --> 00:38:44,719
You know, that's how it works. So what we did is essentially we tried to reconstruct that from

423
00:38:44,719 --> 00:38:50,400
part. So we made neurons that have some of these receptors, including receptors for pain.

424
00:38:50,400 --> 00:38:54,799
So, you know, the receptors for pain actually respond to capsacing, you know, red hot chili pepper,

425
00:38:54,799 --> 00:38:59,839
that's why it's going to be a hot. So they have the specialized receptors and you add capsacing and

426
00:38:59,839 --> 00:39:04,879
they just beautifully respond like electrically. But this had never been witnessed before.

427
00:39:05,599 --> 00:39:09,920
No, I mean, to put the entire circuit together has never really been done before. Now,

428
00:39:09,920 --> 00:39:15,519
the biology of you to witness this the first ever time. Well, the most beautiful part of it was to

429
00:39:15,519 --> 00:39:20,320
be honest, once we made the parts which took us years, you know, the four parts of the circuit and

430
00:39:20,320 --> 00:39:24,480
then put them together and it takes about a hundred days to make them, by the way, and then another

431
00:39:24,480 --> 00:39:28,559
hundred days for the cells to connect with each other. And then at one point, we started like

432
00:39:28,559 --> 00:39:33,200
looking at them and seeing like what's going on. And we've discovered something, you know, really

433
00:39:33,200 --> 00:39:39,200
remarkable. The cells in the circuit become synchronized with each other. So initially, there were

434
00:39:39,199 --> 00:39:44,960
all sparkling, you know, in a non coordinated way. And then at one point, the activity just seems

435
00:39:44,960 --> 00:39:51,759
to be starting on one side and it goes, you know, one unit direction. So the circuit is almost,

436
00:39:51,759 --> 00:39:56,319
you know, and there's no stimulus, by the way, you know, it's almost like which we know also from

437
00:39:56,319 --> 00:40:00,639
brain development that the brain prepares itself before it even receives sensory inputs for what is

438
00:40:00,639 --> 00:40:05,519
about to come. It's almost like practicing. So it's practicing to add, you know, the stimulus. And

439
00:40:05,519 --> 00:40:10,400
then the relevance for pain is that there are this interesting, maybe you've heard about this,

440
00:40:10,400 --> 00:40:15,440
neurologists discovered them, you know, in the past 20 years. There are these patients that have

441
00:40:15,440 --> 00:40:21,199
mutations that make them either completely insensitive to pain. So they literally feel no pain.

442
00:40:21,920 --> 00:40:26,559
And it's really caused by a mutation in a channel, in a sodium channel, or they have the opposite.

443
00:40:27,199 --> 00:40:31,039
They have this channel high-percentive. So they're high-percentive to pain. Both of them are

444
00:40:31,039 --> 00:40:36,800
obviously very bad. So now what we did, we used CRISPR because we were talking about CRISPR before.

445
00:40:36,800 --> 00:40:41,519
And genetically modified the cells in a dish to have the mutations that are present in patients.

446
00:40:42,239 --> 00:40:47,360
Then put them together all four and started watching to see what happens. And in the patients that

447
00:40:47,360 --> 00:40:52,559
have that high-percentive to pain, they're very sensitive to pain, you just see the information

448
00:40:52,559 --> 00:40:57,679
going really, really fast. The cells are super active and they sense it. But in the ones that have

449
00:40:57,679 --> 00:41:02,719
no pain, it's not like there's no activity at all. Actually what we found is there's a lack of

450
00:41:02,719 --> 00:41:08,319
coordination. The cells are essentially like lost that coordination. So that's why it's so important

451
00:41:08,319 --> 00:41:14,000
to have the parts because really at the end of the day, you know, the brain is more than the sum of

452
00:41:14,000 --> 00:41:18,480
its parts, obviously. And so clearly in order to understand some of these disorders, we're going to

453
00:41:18,480 --> 00:41:22,559
need to have some of these parts put together to get these emergent new properties.

454
00:41:23,119 --> 00:41:26,400
And just feeling pain, that's the new, that's the know the kind of movie isn't it?

455
00:41:26,400 --> 00:41:31,199
Yeah, but you know, I mean, we see this in certain people that, okay, I remember we did on the

456
00:41:31,199 --> 00:41:39,360
TV show and Neil has this crazy thing. He can stick his hand in water, ice water. I'm not,

457
00:41:39,360 --> 00:41:45,599
and I'm not saying it right. Take a bunch of ice, add water to it and it actually becomes

458
00:41:45,599 --> 00:41:47,840
colder than freezing, okay? Yes.

459
00:41:47,840 --> 00:41:54,720
All right. Then you put your hand in it and it burns your hand. So we did an experiment and

460
00:41:54,720 --> 00:42:00,800
I stuck my hand in and he stuck his hand in and literally my hand started burning in what a normal

461
00:42:00,800 --> 00:42:07,840
person would have their hand burn. And then he was able to leave his hand in there for a god-awful

462
00:42:07,840 --> 00:42:13,039
amount of time to the point where this is all you were squealing at the time. Well, yes, I was

463
00:42:13,039 --> 00:42:18,480
because it burned. It was not cool. So not literally burned because it's cold, not hot.

464
00:42:18,480 --> 00:42:23,840
Right. It's not literally burned. But it felt like it was burning. Okay. But for you for some

465
00:42:23,840 --> 00:42:28,239
reason, and you know, I just talked it up to you. He got a lot more fat on his hands to get.

466
00:42:30,400 --> 00:42:36,800
But seriously, it's a matter of sensitivity to pain. No, no, it is not. No, what is it?

467
00:42:37,760 --> 00:42:43,200
I didn't say I didn't feel the pain. It is just that I could deal with it. Oh,

468
00:42:44,880 --> 00:42:48,880
well, that just changes everything. Oh, no, that's okay. So explain to me the mind of a match

469
00:42:48,880 --> 00:42:54,560
a respect here. That's a great point actually because you see this is not the only pathway for pain.

470
00:42:54,560 --> 00:42:58,880
It turns out that we have at least two pathways in the brain. One of them allows you to tell

471
00:42:59,760 --> 00:43:04,480
there is a painful stimulus. You know, I sense it. It's on my finger or my hand is in the water,

472
00:43:04,480 --> 00:43:09,280
not my feet. Right. That's the one that tells you that. And then there is a second pathway

473
00:43:09,280 --> 00:43:13,360
that actually leverage other brain regions, the amygdala, the singlet cortex,

474
00:43:14,000 --> 00:43:19,519
that tell you that that is really bad. It gives you the unpleasant feeling, the emotional

475
00:43:19,519 --> 00:43:24,960
component of pain. And you know, they're interesting. They're patients who dissociate between the two.

476
00:43:24,960 --> 00:43:30,400
So their patients do, let's say, have a stroke or a tumor in the insula or in the singlet cortex.

477
00:43:30,480 --> 00:43:34,639
And you'll have this patient and they'll tell you, you know, I know you're, you know,

478
00:43:34,639 --> 00:43:39,840
you're hurting like my finger. And I can tell you that it is my finger, but it doesn't feel unpleasant

479
00:43:39,840 --> 00:43:45,119
at all. So this pathways are dissociated in the brain. Now, in the work that we've done,

480
00:43:45,119 --> 00:43:50,800
we've reconstructed the basic pathway that just processes pain stimuli, not the emotional

481
00:43:50,800 --> 00:43:55,360
component. So we wouldn't say that they're feeling pain in any way, right? Just to make it clear,

482
00:43:55,360 --> 00:44:00,000
because as you can imagine, there are kind of other ethical issues that are arising from like most

483
00:44:00,000 --> 00:44:05,679
of the work that we do, obviously, because you know, we want our models to be closer to the

484
00:44:05,679 --> 00:44:10,639
human brain because we think that many of the psychiatric disorders are uniquely human. And yet,

485
00:44:10,639 --> 00:44:15,440
the more the closer they are to the human brain, the more uncomfortable we feel, right? So I think

486
00:44:15,440 --> 00:44:20,159
it's so like mitigating this risk moving forward that I think is very important. How do you now

487
00:44:20,159 --> 00:44:28,960
having had this experience with the sensory aspect of it, reverse engineer again, the way to

488
00:44:28,960 --> 00:44:35,360
get a drug to alleviate the hypersensitivity to pain? Sure. I mean, there are many ways that you

489
00:44:35,360 --> 00:44:40,400
can do this. So like, no, think about it. Scott Scott. Well, not everybody, everybody's got to

490
00:44:40,400 --> 00:44:46,960
think with opioids, but there must be a mechanism there where opioids use that you can sort of tag

491
00:44:46,960 --> 00:44:52,400
on to, but not get that addictive part. Exactly. And think about it, like it's sad that the best,

492
00:44:52,400 --> 00:44:57,039
the best treatment that we have for like pain comes out of like poppy season,

493
00:44:57,039 --> 00:45:00,559
and what discovered thousands of years ago by chance, right? I mean, essentially piggybacks on

494
00:45:00,559 --> 00:45:06,239
this circuit does not come from a deep understanding of the circuit itself. Don't you make opium from

495
00:45:06,239 --> 00:45:11,679
poppy seeds? Yes. Okay. Just want to clarify that. Yeah. So I think the idea now is that we have

496
00:45:11,679 --> 00:45:16,800
the circuit in a dish. You can add opioids by the way and see how they modulate this and see,

497
00:45:16,800 --> 00:45:22,000
okay, this is what opioids do to the circuit. But let's now try to do the same thing in a different

498
00:45:22,480 --> 00:45:27,679
way, right? One that is sort of like, you know, driven by the biology behind it. And I think

499
00:45:27,679 --> 00:45:32,320
that's the beauty of it. That is a beauty. And by the way, a professor, if you ever get to that

500
00:45:32,320 --> 00:45:38,880
place, please email me right before you make that public because I would like to be the first investor

501
00:45:40,719 --> 00:45:48,239
in the pain free opiate that is non addictive because that is, I mean, that's the end of the game

502
00:45:48,239 --> 00:45:52,959
right there. And just to be clear, Chuck, what? Because when my hand was I just want to like,

503
00:45:52,959 --> 00:45:58,479
get back to my hand in the bucket. Yeah. Okay. Long ago, right when I began wrestling in high school.

504
00:45:58,479 --> 00:46:02,079
And I was going to bring this up. I think it's because you were an athlete and athletes have to

505
00:46:02,079 --> 00:46:08,000
deal with pain all the time. Exactly. And I judge by looking at the situation, is this pain,

506
00:46:08,000 --> 00:46:13,599
something that will cause irreparable damage or is it just simply pain? Okay. And I'm looking at

507
00:46:13,679 --> 00:46:19,519
my hand is in a bucket of ice. Yeah, it hurts. But I love who cares. I'm not going to get

508
00:46:19,519 --> 00:46:25,119
frostbite from it. Okay. So you and Gary have that I'm sure because Gary's had a ton of surgery.

509
00:46:25,119 --> 00:46:31,599
We have not played in pain. He sat in ice after games. Right. See, and I have not played

510
00:46:31,599 --> 00:46:36,799
in none of that. I've done none of that. And this is you play. That's why you went out in the time

511
00:46:36,799 --> 00:46:43,440
of me because this is how pain works for me. Okay. The way pain works for me is I experience it

512
00:46:43,759 --> 00:46:51,360
and then my brain, my body and everything in my soul goes, Jesus, no, please Lord, no. So,

513
00:46:59,039 --> 00:47:05,759
so when when you're saying you're you're building these avatars and the detective work that comes,

514
00:47:05,759 --> 00:47:12,079
are you finding more clues and more answers or are you just finding clues and then we've got to sit

515
00:47:12,079 --> 00:47:16,639
there, scratch your heads and hopefully come up with an answer. Or is this really empowering

516
00:47:16,639 --> 00:47:21,519
the sort of psychiatric research that you're interested in? You know, the way I look at it is,

517
00:47:21,519 --> 00:47:26,799
you know, psychiatric disorders have been a mystery like no doubt. I mean, how does complex

518
00:47:26,799 --> 00:47:33,119
behavior or hallucination arises from the brain in mesmerizing us for such a long time? And it's

519
00:47:33,119 --> 00:47:38,480
almost like if you were to think about it, it's almost as like seeing, you know, Egyptians riding

520
00:47:38,639 --> 00:47:42,960
for the first time, right? You look at them, you know, where do you even start? I mean,

521
00:47:42,960 --> 00:47:47,199
they're beautiful drawings, you know, you could classify them based on like the animals,

522
00:47:47,199 --> 00:47:52,159
but then you can make sense of what the meaning is. And you see, that's why, you know, if you think

523
00:47:52,159 --> 00:47:57,199
about it, like historically, the discovery of the Rosetta stone, right? Like this tiny piece

524
00:47:57,199 --> 00:48:02,960
tablet that for the first time had ear glips on one side and Greek riding on the other one,

525
00:48:02,960 --> 00:48:07,760
right? And then, you know, this French scientist, we came with Napoleon, finds this,

526
00:48:07,760 --> 00:48:13,200
starts looking at it. And that becomes essentially the, you know, enabling tool.

527
00:48:13,200 --> 00:48:16,800
Suddenly, we could actually see what word does what? And you know, cool thing about the Rosetta

528
00:48:16,800 --> 00:48:21,440
stone. It's like a shopping list or something. It's like, it's not really any deep, just like

529
00:48:21,440 --> 00:48:27,200
bread eggs. I don't know exactly a shopping list, but it's something completely very, very

530
00:48:27,200 --> 00:48:32,640
yet, but yeah, really trivial. Absolutely. And yet, like, it was the only riding that we know

531
00:48:32,640 --> 00:48:37,280
that have both on both sides. So I think the question is, we need to somehow translate that one

532
00:48:38,080 --> 00:48:42,080
point. So like this mental processes that are so complex into what we can deal with, which is

533
00:48:42,080 --> 00:48:46,560
really molecular biology. That's what we can control. Well, like, molecular biology, we can control.

534
00:48:46,560 --> 00:48:51,280
So I think, you know, to a large extent, I've seen this like the, the mission, you know,

535
00:48:51,280 --> 00:48:55,360
for my lab. And in general, like I think for the community more broadly, is really to try

536
00:48:55,360 --> 00:49:00,720
to translate some of this complex phenomena of the brain in very simple processes,

537
00:49:00,720 --> 00:49:05,680
calcium in a neuron, you know, tuneros connecting with each other. And then, hopefully by doing that,

538
00:49:05,679 --> 00:49:10,480
and finding ways of reversing it, those will also reverse at least improve. We don't know that,

539
00:49:10,480 --> 00:49:14,799
you know, we, we, you know, that has not yet been done. And, you know, we'll have to see what the

540
00:49:14,799 --> 00:49:17,679
clinical trial will actually be successful. I mean, we're preparing for clinical trial for

541
00:49:17,679 --> 00:49:22,480
Timothy syndrome right now. We're still like in the last stages of preparation. We found most of the

542
00:49:22,480 --> 00:49:26,879
patients in the world were building a special unit here, Stanford, where we're going to be

543
00:49:26,879 --> 00:49:31,199
hopefully bringing them in the next year or so and doing the clinical trial. So we'll see. And then,

544
00:49:31,199 --> 00:49:35,359
you know, this is the first disease. I mean, and I look at Timothy syndrome, so like really being

545
00:49:35,360 --> 00:49:39,840
the first first, but we have half a dozen of other conditions that we've been studying from various

546
00:49:39,840 --> 00:49:45,599
angles. Really, I mean, I see this, this is going to be the golden age for human neuroscience.

547
00:49:45,599 --> 00:49:52,320
And I'm delighted to learn that you're putting in this much effort for a disease that is so rare.

548
00:49:52,320 --> 00:49:56,720
Yeah. I mean, think about that. So the rarity, at least the people have the benefit of your

549
00:49:56,720 --> 00:50:02,960
attention given to it. Yeah. Rather than someone just making the cost benefit analysis. And say,

550
00:50:02,960 --> 00:50:06,880
we're not doing anything. We're not going there. We're not going down that. Right. Yeah. Right.

551
00:50:06,880 --> 00:50:09,519
So I'll be saying here that your

552
00:50:10,159 --> 00:50:15,679
assembly research and work is going to be the key to understanding what has been hidden

553
00:50:15,679 --> 00:50:21,599
brain biology. How soon do you think maybe you really will be able to not just tick off the

554
00:50:21,599 --> 00:50:26,559
Timothy syndrome, but take on other horrific diseases? Oh, we're already working on others.

555
00:50:27,199 --> 00:50:31,119
I mean, you know, at least half a dozen we've been studying. Like some are associated with

556
00:50:31,119 --> 00:50:35,440
epilepsy, somewhat intellectual disability. We have a few forms of schizophrenia. So we didn't

557
00:50:35,440 --> 00:50:39,039
deploying this like systematically. And another thing that we've done to be honest, and this is sort

558
00:50:39,039 --> 00:50:44,719
like being in the spirit of what we do at Stanford is, you know, I lead us to a center here.

559
00:50:44,719 --> 00:50:48,559
And in the beginning, it was, you know, there was when we published some of the first methods,

560
00:50:48,559 --> 00:50:52,559
everybody was like, Oh, you know, can we come to the lab and learn how to do it? Like we want to do

561
00:50:52,559 --> 00:50:57,440
it too. And we brought people here initially, but at one point, you know, we couldn't train

562
00:50:57,440 --> 00:51:03,920
enough people. So we actually started doing literally courses where we bring students from all

563
00:51:03,920 --> 00:51:09,119
over the world from various labs. And for about a week, almost like in a cooking show, if you

564
00:51:09,119 --> 00:51:12,559
want to think about it, right? Because you know, the experiments are done before. We just show them,

565
00:51:12,559 --> 00:51:17,440
this are the critical steps that you need to do. And so we've been helping more than 300 labs

566
00:51:17,440 --> 00:51:23,039
around the world to, you know, implement this method. And if the breakthrough is not going to come

567
00:51:23,119 --> 00:51:28,239
from my lab, therapeutically speaking, that's fine. Because it will probably come from somebody else,

568
00:51:28,239 --> 00:51:33,279
somewhere like, you know, in a corner of Europe or who knows of South America doing experiments on

569
00:51:33,279 --> 00:51:37,440
a rare form of disease and finding a therapeutic, that would be fine. I think because there's so much to

570
00:51:37,440 --> 00:51:43,199
do for, you know, one in four individuals is suffers from a psychiatric disease today. All right.

571
00:51:43,199 --> 00:51:49,279
It's a huge burden. Are we going to come across a situation where you are going to have you be

572
00:51:49,280 --> 00:51:54,080
faced with building an assembler, it or creating an assembler that will just be too complex?

573
00:51:54,800 --> 00:52:00,560
Is there a limit to what you can assemble? There are absolutely limits to what we can assemble.

574
00:52:00,560 --> 00:52:04,880
And, you know, while like many of the features of this assembler is really fascinating and

575
00:52:04,880 --> 00:52:09,840
surprising, you know, they still have a lot of limitations. You know, I mean, they're not

576
00:52:09,840 --> 00:52:15,600
vasterized. They don't receive blood supply. We may be able to stimulate them with like

577
00:52:15,679 --> 00:52:20,239
capsules and something else, but they're not receiving the rich sensory information that is important.

578
00:52:20,239 --> 00:52:26,480
You know, think about the, you know, if you have a kitten where you, you know, you cover one eye,

579
00:52:26,480 --> 00:52:31,519
you cover that eye for a week, that cat will never see with that eye. You do it in an adult cat

580
00:52:32,159 --> 00:52:38,400
for a week, no problem whatsoever. So early in development, if some of the circuits do not

581
00:52:38,400 --> 00:52:44,159
receive the right input, they won't develop properly. So, you know, again, while our models are

582
00:52:44,159 --> 00:52:49,839
relatively complex already, they lack a lot of the complexity. And, you know, is as George

583
00:52:49,839 --> 00:52:56,000
box famously said, that all models are wrong or some are useful, you know, and the models that we make

584
00:52:56,000 --> 00:53:01,519
are not, our goal is not to make a perfect model of the brain. It's like to make a good enough

585
00:53:01,519 --> 00:53:06,159
model of a part of a brain over a circuit that will give us the brain through therapeutically.

586
00:53:06,159 --> 00:53:11,839
I wouldn't be so harsh with the term model there. I would say all models are almost by construct

587
00:53:11,920 --> 00:53:17,120
incomplete, right? But that wouldn't make them wrong necessarily. They're just, they're not the

588
00:53:17,120 --> 00:53:21,360
whole story. That's why they're a model. Otherwise would be the exact thing. You would need it.

589
00:53:21,360 --> 00:53:25,200
You would need a model if you could replicate the exact thing. It would be the thing. Right.

590
00:53:25,200 --> 00:53:30,640
It's all right. Yeah. Okay. Yeah. I just love that assembloids sounds like a cartoon network show.

591
00:53:31,280 --> 00:53:35,760
Like assembloids weekdays at three right after Transformers. You know, it's actually

592
00:53:35,760 --> 00:53:40,400
that's how there is a game. There is a video game for it, which I didn't know when I put out the

593
00:53:40,400 --> 00:53:44,400
term, but there is a very popular video game that is literally called assemblids. Cool.

594
00:53:45,680 --> 00:53:51,119
Where do we hit the ethical wall and hit the regulatory and all the other things? And

595
00:53:51,680 --> 00:53:57,519
do you say regulatory? I did. This America Jack is regulatory. I'm not even regulatory.

596
00:53:57,519 --> 00:54:05,200
I'm not even regulatory. I didn't come here for a lecture on geography. I know it's America.

597
00:54:05,199 --> 00:54:11,439
It's a murky Jack. Anyway, we were saying, you know, we think about this like all the time.

598
00:54:11,439 --> 00:54:15,679
Honestly, in the beginning, obviously, they're like not that many ethical issues, but as we've

599
00:54:15,679 --> 00:54:20,799
progressed, it becomes clear that we have to think carefully. So they're like, you know, the way

600
00:54:20,799 --> 00:54:25,359
I think I was is like in multiple levels. Like on one hand, they're like issues about the cells.

601
00:54:25,919 --> 00:54:29,839
These are human cells that we're using. Yeah. You know, who owns the cells? You have to give

602
00:54:29,839 --> 00:54:34,159
consent for this experiment to be done. And we do that all the time. And so we always have to put

603
00:54:34,159 --> 00:54:38,719
that into the context of like, what are we doing with the cells? What the cells were consented for?

604
00:54:38,719 --> 00:54:42,639
That's very much like who is the woman who lacks? What's her name?

605
00:54:43,199 --> 00:54:52,399
Wax. Lax. Yes. Whose cancer cells were? Who's used for decades and saved and created many

606
00:54:52,399 --> 00:54:58,719
breakthroughs in cancer. And the family got nothing. And she never gave permission. So it's good

607
00:54:58,719 --> 00:55:01,759
to know you're doing that. And that's why it's critical every time with every time we've got

608
00:55:01,760 --> 00:55:06,720
this. Henry had a wax. Henry had a wax. Yes. You know, the patients or, you know, who,

609
00:55:06,720 --> 00:55:11,200
you know, the parents, in the case of their minors will actually be clearly informed about what

610
00:55:11,200 --> 00:55:15,440
will happen with the cells, how the cells will be shared with others, for instance, under what

611
00:55:15,440 --> 00:55:20,160
conditions and so on and so forth. So on one hand, there are like this issues about the cells.

612
00:55:20,160 --> 00:55:24,800
Then sometimes as you know, we're using animals. So sometimes we transplant this into the animal.

613
00:55:24,800 --> 00:55:28,320
So we also have to think about the well for urban animal. I mean, you transplant more is the

614
00:55:28,320 --> 00:55:32,559
animal suffering in any way. And then the third problem, which is perhaps the more con like

615
00:55:32,559 --> 00:55:37,840
philosophical in a way is like, are there any new emergent properties? Like are there,

616
00:55:38,720 --> 00:55:43,120
you know, features, complex features that are rising from this that would make one thing that we

617
00:55:43,120 --> 00:55:48,720
need to regulate this field? Currently, I think the models that we have in feature are not sufficiently

618
00:55:48,720 --> 00:55:55,760
complex to justify, you know, the presence of any complex features. Like that's why we don't

619
00:55:55,760 --> 00:56:01,120
use the term generally, you know, the term intelligence for this because intelligence is really a

620
00:56:01,120 --> 00:56:06,720
property of an organism. It involves like gold directed behavior, involves learning. None of our

621
00:56:06,720 --> 00:56:14,320
cultures do that. And using, you know, anthropomorphizing, it's not generally a very useful thing to do

622
00:56:14,320 --> 00:56:19,040
in this case. But as the models become more complex, we have to start having this conversations.

623
00:56:19,040 --> 00:56:24,080
And that's why, you know, last year we had an Estilumar meeting, which is like this historic

624
00:56:24,079 --> 00:56:28,639
place here in California, you may have heard where many of this ethical discussions have started

625
00:56:28,639 --> 00:56:34,400
in biology in the 70s when cloning, gene cloning was so like discovered that everybody was like,

626
00:56:34,400 --> 00:56:38,799
what is going to happen? We're now modifying these genes and we're going to create new organisms.

627
00:56:38,799 --> 00:56:44,239
So scientists got together there with philosophers, you know, with journalists. So that's what we're

628
00:56:44,239 --> 00:56:48,559
also doing now. We're getting together a larger group and thinking what are some of the implications?

629
00:56:49,119 --> 00:56:55,279
You know, sociologically, religiously, philosophically, while at the same time, thinking that

630
00:56:56,000 --> 00:57:01,920
psychiatric disorders are a huge burden. And if you have a technology that has the potential

631
00:57:02,559 --> 00:57:08,960
to change that, to provide cures, is it, you know, unethical not to use it? Right? I mean,

632
00:57:08,960 --> 00:57:13,679
there's even that argument, you know, where, you know, how far do we go in that? So that those

633
00:57:13,679 --> 00:57:16,799
are like ongoing discussions. I mean, it's been really interesting. I spend more and more

634
00:57:16,800 --> 00:57:23,200
over my time as part of this conversation. Let me take just one other place before we land the plane

635
00:57:23,200 --> 00:57:32,080
here. You came into this as an expert in the autism spectrum patient. Yes. And a new term that's

636
00:57:32,080 --> 00:57:38,720
been bandied about the last certainly 10 years is the concept of neurodiversity. When you look at it

637
00:57:38,719 --> 00:57:48,239
that way, who was anyone to say that someone needs repair if they're simply manifesting on a

638
00:57:48,239 --> 00:57:56,799
spectrum of neurodiversity? Sure. Your counterparts not long ago would have labeled homosexuality

639
00:57:56,799 --> 00:58:04,079
as a mental disorder in need of repair. And only recently, been historical times recently,

640
00:58:04,079 --> 00:58:11,679
was that removed from the list of human maladies and disorders. So there's an ethical,

641
00:58:12,480 --> 00:58:19,279
another ethical frontier about what it is you judge needs repair versus is just another kind of

642
00:58:19,279 --> 00:58:24,079
person. And that's absolutely one of the discussions that we've been having, one of the ethical

643
00:58:24,079 --> 00:58:28,400
discussions that we've been having. And you know, all psychiatric disorders are on a spectrum with

644
00:58:28,400 --> 00:58:33,440
the population. And some of them are more severe and some of them are less severe. And that's also the

645
00:58:33,440 --> 00:58:41,679
case for autism. You know, autism is certainly a spectrum. But what we're focusing on is actually

646
00:58:41,679 --> 00:58:47,760
what we now call profound autism. This is the autism that is really debilitating. So patients with

647
00:58:47,760 --> 00:58:51,920
Timothy syndrome or like some of the other patients that were like with other disorders can have

648
00:58:51,920 --> 00:58:59,599
60 seizures a day. Oh, really? That's just they are unable to make any eye contact. They need a

649
00:58:59,599 --> 00:59:05,279
caregiver for the rest of their life. You know, the biggest fear that a parent has when they have,

650
00:59:05,279 --> 00:59:11,599
you know, a child is like, what if I die? So I am seeing it through the eyes of some of this

651
00:59:11,599 --> 00:59:16,880
parents that are dealing with like really the devastating forms of autism, what we call profound

652
00:59:16,880 --> 00:59:23,039
autism. And then of course, there is like what you mentioned, which are neurotypical or,

653
00:59:23,839 --> 00:59:28,400
you know, aspects of how we interact with each other that do not require any, nobody wants

654
00:59:29,039 --> 00:59:35,519
to cure or to provide treatment for anybody. But this patient are severely affected. Most

655
00:59:35,519 --> 00:59:40,400
patients with psychiatric disorders are severely affected. So I once asked Oliver Sacks,

656
00:59:40,400 --> 00:59:46,320
who is a friend of our show. We have some archival content with him. Oh, that's amazing. Yeah,

657
00:59:46,320 --> 00:59:53,680
yeah. I asked him after a public talk that he gave, if you could go back in time and carry with

658
00:59:53,679 --> 01:00:00,960
you a pill that would cure your own elements, uh, get sort of certain neuro issues. Uh, he has,

659
01:00:01,759 --> 01:00:07,919
correct me on the word here, prognoplagnesia. Yes, he did. Yeah, he couldn't really identify

660
01:00:07,919 --> 01:00:13,759
the face blindness. Okay. Oh, wow. And and some other elements to it. Sometimes wish I had that.

661
01:00:13,759 --> 01:00:19,359
Oh, okay. So, so I asked him, if you could take a pill that would just cure that back when you were

662
01:00:19,360 --> 01:00:26,800
17, would you looking back at that time? And he said, no, because it was that those differences in

663
01:00:26,800 --> 01:00:33,200
the way his mind worked, they got him interested in neuroscience. That was his destiny. But,

664
01:00:33,200 --> 01:00:38,240
but you see, that's exactly, you know, the point where we started, like the beauty of like building

665
01:00:38,240 --> 01:00:44,160
a nervous system is that while there is a basic plan that makes our brains the same, we pretty

666
01:00:44,239 --> 01:00:50,480
might, you know, can do the same things. It also creates a lot of diversity, even monozigotic twins,

667
01:00:50,480 --> 01:00:56,319
right? I have the same genetic, uh, you know, material, they share the same womb. Yeah. And then

668
01:00:56,319 --> 01:01:00,239
they can have different sexual orientations, you know, they like, they have different hobbies.

669
01:01:00,239 --> 01:01:04,559
They have different fingerprints, if I remember correctly, don't they? They do. They do. Yes.

670
01:01:04,559 --> 01:01:09,519
Wow. Because again, there is a lot of stochastic forces in development. And those are the,

671
01:01:09,519 --> 01:01:13,839
those are the ones that make us different. And that's how evolution actually works too. You know,

672
01:01:13,920 --> 01:01:18,960
by selecting these differences that, yeah, I mean, to large extent probably that's what made us

673
01:01:18,960 --> 01:01:24,000
as a species so successful. Yeah. The fact that there's always an individual who has a vision,

674
01:01:24,000 --> 01:01:29,840
who wants to go and, you know, discover a new continent. Yeah. So I think that's the power of our

675
01:01:29,840 --> 01:01:36,880
species. And I think I know very few, honestly, psychiatrist or neurologist who would want to cure

676
01:01:36,880 --> 01:01:41,200
that or change that. Right. Right. I think what we're dealing really on the field is really

677
01:01:41,199 --> 01:01:47,279
this devastated conditions that make essentially most of this children unable to really function as

678
01:01:47,279 --> 01:01:52,799
as adults or as children. So it's a very human human-centric view. So if you were the,

679
01:01:52,799 --> 01:01:58,480
the COVID virus, you would say, let's invent humans who then have airplanes so that we can cross

680
01:01:58,480 --> 01:02:06,000
continents and affect other people. Absolutely. They are the true owners of this planet.

681
01:02:06,079 --> 01:02:09,679
Let's be on the virus. They're true owners of this planet.

682
01:02:09,679 --> 01:02:15,199
Micrubs. We're just a new bus. Yeah. That's all. We're just an Uber ride. Well,

683
01:02:15,199 --> 01:02:21,519
Sergio, it's been a delight to have you on StarTalk sharing your expertise with us and taking time

684
01:02:21,519 --> 01:02:27,039
out of what we know is your busy research schedule. Give us a little glimpse into what you're doing

685
01:02:27,039 --> 01:02:31,679
in your lab. Just congratulations to you and all the people who work in your lab who are surely

686
01:02:32,399 --> 01:02:36,000
working there right now while you're talking to us. Right here. I mean, yeah.

687
01:02:37,440 --> 01:02:41,519
And really, they're the ones doing well in the work. I mean, you know, this work, I mean,

688
01:02:41,519 --> 01:02:46,159
hopefully it came through from the discussions, but this experiments are long. I mean, they last

689
01:02:46,159 --> 01:02:51,039
hundreds of days because human element it takes a long time. So it requires a lot of dedication.

690
01:02:51,039 --> 01:02:56,480
And I, but I think the promise of what this could yield ultimately, you know, understanding

691
01:02:56,559 --> 01:03:01,199
the human brain is, you know, is addictive. So, you know, we really want to figure this out.

692
01:03:01,199 --> 01:03:07,280
Well, thank you again. I'd like to reflect on this with a brief cosmic perspective. If I may,

693
01:03:07,280 --> 01:03:12,000
please. This moving neuroscience frontier has got me thinking.

694
01:03:13,920 --> 01:03:20,079
We look at the progress of civilization. It always comes about when we have the proper match

695
01:03:21,039 --> 01:03:31,920
between the tool and a goal. And when they come together, we build thing that didn't exist before.

696
01:03:33,759 --> 01:03:40,639
But we disassemble things that had never been taken apart before. But in all cases, it has to do

697
01:03:41,360 --> 01:03:48,880
with the precision of the tools you bring to the task. And to learn what's going on on the frontier

698
01:03:49,680 --> 01:03:59,440
of neuroscience, it feels to me that it's finally catching up with the methods and tools that

699
01:03:59,440 --> 01:04:04,880
have shaped engineering throughout the history of civilization. Engineers built

700
01:04:06,160 --> 01:04:13,840
dams and building and aqueducts and everything that we value and care about in our modern life.

701
01:04:14,480 --> 01:04:22,079
But the time has come to care about what's going on inside our brain within our mind. And I'm

702
01:04:22,079 --> 01:04:30,400
delighted to learn that that is a frontier that finally has tools befitting the task.

703
01:04:32,240 --> 01:04:40,800
Welcome to the club. Neuroscience. And that is a cosmic perspective. Keep looking up.

