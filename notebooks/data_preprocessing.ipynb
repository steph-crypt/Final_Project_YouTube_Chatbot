{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a14a88",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d45a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ First 5 segments of: /Users/test/Desktop/ironhack_labs/Final_Project_YouTube_Chatbot/transcripts/01 - Is The Universe Made of Tiny Vibrating Stringsï¼Ÿ With Lara Anderson.json\n",
      "\n",
      "[0.00s - 5.00s]  Could such extra dimensions exist, and if so, how would we try and probe whether that's the case?\n",
      "[5.00s - 11.00s]  If you imagine looking at an extended object like a wire, it just looks one-dimensional, it just looks like it has a length.\n",
      "[11.00s - 15.00s]  But if you were able to get really close to that wire, you'd see that it also has something like a thickness.\n",
      "[15.00s - 18.00s]  And so that extra direction is what's called compact.\n",
      "[18.00s - 21.00s]  Is it possible to have a compactified time dimension as well?\n"
     ]
    }
   ],
   "source": [
    "def read_transcript_head(json_path, num_segments=5):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"\\nðŸ“„ First {num_segments} segments of: {json_path}\\n\")\n",
    "    \n",
    "    for segment in data.get('segments', [])[:num_segments]:\n",
    "        start = segment['start']\n",
    "        end = segment['end']\n",
    "        text = segment['text']\n",
    "        print(f\"[{start:.2f}s - {end:.2f}s] {text}\")\n",
    "\n",
    "read_transcript_head('/Users/test/Desktop/ironhack_labs/Final_Project_YouTube_Chatbot/transcripts/01 - Is The Universe Made of Tiny Vibrating Stringsï¼Ÿ With Lara Anderson.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e6aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "#set openAI api key\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050bf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import CSVLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06079e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename  start    end  \\\n",
      "0  02 - Astrophysicists Discuss Issues with Gravi...   0.00   1.38   \n",
      "1  02 - Astrophysicists Discuss Issues with Gravi...   1.38   5.80   \n",
      "2  02 - Astrophysicists Discuss Issues with Gravi...   5.80   8.24   \n",
      "3  02 - Astrophysicists Discuss Issues with Gravi...   8.24  11.96   \n",
      "4  02 - Astrophysicists Discuss Issues with Gravi...  11.96  12.64   \n",
      "\n",
      "                                                text  \n",
      "0                                    Dunkle Materie.  \n",
      "1   Ja, was wir dunkle Materien nennen, ist gewÃ¶h...  \n",
      "2   deren Schwerkraft in unser Universum Heinin w...  \n",
      "3   Es gibt eine Dimension, die aus diesem Univer...  \n",
      "4                                             Punkt!  \n"
     ]
    }
   ],
   "source": [
    "import langchain as lc\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your dataset\n",
    "\n",
    "def load_transcripts_to_df(json_dir):\n",
    "    all_rows = []\n",
    "\n",
    "    for filename in os.listdir(json_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(json_dir, filename)\n",
    "\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            segments = data.get('segments', [])\n",
    "            for seg in segments:\n",
    "                all_rows.append({\n",
    "                    'filename': filename,\n",
    "                    'start': seg.get('start'),\n",
    "                    'end': seg.get('end'),\n",
    "                    'text': seg.get('text')\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "# Use the function\n",
    "json_dir = '/Users/test/Desktop/ironhack_labs/Final_Project_YouTube_Chatbot/transcripts'\n",
    "df_transcripts = load_transcripts_to_df(json_dir)\n",
    "\n",
    "# View the first few rows\n",
    "print(df_transcripts.head())\n",
    "\n",
    "# # Example of data preprocessing\n",
    "# preprocessed_data = lc.prepare_data(data)\n",
    "\n",
    "# # Display the first few rows of the preprocessed data\n",
    "# print(preprocessed_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sftenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
